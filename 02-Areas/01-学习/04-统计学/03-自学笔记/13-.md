# 标准分数、偏度与峰度

## 标准分数 (Standard Score / Z-score)
![image.png](https://raw.githubusercontent.com/SAMLAY-c/obsidian-photos/university/img/20250503021851028.png)

* **定义与过程：**
    * 每组数据有自己的均值和标准差。
    * 将数据中的每个数值减去该组数据的均值，再除以该组数据的标准差。
    * $z_i = \frac{x_i - \bar{x}}{s}$ (样本) 或 $z_i = \frac{x_i - \mu}{\sigma}$ (总体)
* **结果：** 得到的数值称为**标准分数**或**标准化值** ($z_i$)。
* **性质：**
    * **无量纲：** 单位被消掉（分子分母单位相同），是一个纯数值。
    * **不改变数据的相对位置：**
        * 减均值：数据整体平移，相对位置不变。
        * 除标准差（>0）：数据等比例缩放（压缩/拉伸），相对位置不变。
* **作用：**
    * **度量一个数值在数据中的相对位置：** $z_i$ 表示 $x_i$ 距离均值多少个标准差，方向如何。
        * $z_i > 0$: $x_i$ 大于均值。
        * $z_i < 0$: $x_i$ 小于均值。
        * $|z_i|$ 越大：$x_i$ 离均值越远。
    * **判断离群点 (Outliers)：** 通常基于相对位置判断。
        * 经验法则：若 $|z_i| > 3$，则 $x_i$ 可能是离群点（数据点距均值超过3个标准差）。
    * **对变量进行标准化处理：** 将不同量纲、不同均值/标准差的数据转换为可比的形式。
* **数学特征：**
    * 标准分数的均值为 0 ($\bar{z} = 0$)。
        * 证明：$\bar{z} = \frac{1}{n} \sum z_i = \frac{1}{n} \sum \frac{x_i - \bar{x}}{s} = \frac{1}{ns} \sum (x_i - \bar{x}) = \frac{1}{ns} \cdot 0 = 0$ (因离均差之和为 0)。
    * 标准分数的标准差为 1 ($s_z = 1$)，方差为 1 ($s_z^2 = 1$)。
        * 证明：$s_z^2 = \frac{\sum (z_i - \bar{z})^2}{n-1} = \frac{\sum (z_i - 0)^2}{n-1} = \frac{\sum z_i^2}{n-1} = \frac{\sum (\frac{x_i - \bar{x}}{s})^2}{n-1} = \frac{\sum (x_i - \bar{x})^2}{s^2 (n-1)}$
        * 又 $s^2 = \frac{\sum (x_i - \bar{x})^2}{n-1}$，所以 $\sum (x_i - \bar{x})^2 = s^2 (n-1)$。
        * $s_z^2 = \frac{s^2 (n-1)}{s^2 (n-1)} = 1$。因此 $s_z = \sqrt{1} = 1$。
    * 标准化后的数据再进行标准化，结果不变 (仍是原标准分数 $z_i$)。

## 偏度 (Skewness) 与 峰度 (Kurtosis)

### 偏度 (Skewness)

* **关注：** 数据分布的形状。
* **定义：** 衡量数据分布的**不对称性**（偏斜的方向和程度）。
* **偏度系数 (Skewness Coefficient, $SK$)：** 度量不对称性的统计量。
* **$SK$ 的符号与方向：** $SK$ 可正、可负、可为零。
    * 符号主要取决于**离均差的立方和** $\sum (x_i - \bar{x})^3$。
    * $(x_i - \bar{x})^3$: 若 $x_i < \bar{x}$ 为负，若 $x_i > \bar{x}$ 为正。
    * **对称分布：** 正负抵消，$SK = 0$。
    * **不对称分布：** 符号由占优势的一方决定。
        * **右偏 / 正偏 ($SK > 0$)：** 尾巴在**右边**。右侧离差立方和占优（常因右侧有极端值）。分布图形左高右低。
        * **左偏 / 负偏 ($SK < 0$)：** 尾巴在**左边**。左侧离差立方和占优（常因左侧有极端值）。分布图形右高左低。
    * **记忆：** 尾巴在哪边，偏度符号就与哪边一致（正/负），分布就往哪边偏。
* **$SK$ 的程度与计算：**
    * 衡量偏斜的**程度**，通过比较 $|SK|$ 的绝对值。
    * 计算公式包含标准化和平均化：考虑了 $\sum z_i^3$ 并进行归一化（消除数据取值、波动、样本量影响）。
    * **解释标准 (经验法则)：**
        * $0 < |SK| \le 0.5$: 轻微偏斜。
        * $0.5 < |SK| \le 1$: 中等偏斜。
        * $|SK| > 1$: 严重偏斜。

### 峰度 (Kurtosis)

* **关注：** 数据分布的形状（**峰的尖峭程度**和**尾部的厚度**）。
* **峰度系数 (Kurtosis Coefficient, $K$)：** 度量峰度和尾部特征的统计量。
* **参考点：** 正态分布的峰度通常定义为 0 （使用**超额峰度** $K-3$），或公式计算结果为 3。讲义中暗示是计算结果减 3，使正态分布为 0。
* **关键决定因素：** 标准化离差的**四次方和** $\sum z_i^4$。四次方更突出离均值远的数据。
* **测量本质：** 主要衡量分布的**尾部厚度**。尾部越厚，极端值占比越大，峰度越大。
* **解释 (与正态分布比较)：**
    * $K > 0$ (超额峰度为正)：**尖峰分布 (Leptokurtic)**。峰比正态分布更尖，**尾巴更厚**。
    * $K < 0$ (超额峰度为负)：**扁平分布 (Platykurtic)**。峰比正态分布更平坦，**尾巴更薄**。
    * $K \approx 0$: 接近正态分布的峰度。
* **图像判断注意事项：**
    * **不要**直接看原始数据的分布图。不同标准差的数据，标准差小的图看起来更高，但这不代表峰度更大（峰度已消除了标准差影响）。
    * **必须**看**标准化**后的分布图。
    * 判断核心看**尾巴的厚度**：尾巴越厚（分布越分散到远离均值的区域），峰度越大。
    * 通常后尾伴随尖峰，但严格定义关注尾部厚度。

### 经验法则与切比雪夫不等式

* **经验法则 (只适用于对称分布)：**
    * 约 68% 数据在均值 $\pm 1$ 标准差内 ($|z| \le 1$)。
    * 约 95% 数据在均值 $\pm 2$ 标准差内 ($|z| \le 2$)。
    * 约 99% 数据在均值 $\pm 3$ 标准差内 ($|z| \le 3$)。
* **切比雪夫不等式 (适用于任何分布)：**
    * 概率不等式：数据落在均值 $\pm k$ 标准差内的概率**至少**为 $1 - \frac{1}{k^2}$。
    * $P(|X - \mu| < k\sigma) \ge 1 - \frac{1}{k^2}$ 或 $P(|Z| < k) \ge 1 - \frac{1}{k^2}$
    * 要求 $k > 1$ (否则 $1 - 1/k^2 \le 0$，无意义)。
    * 例子：
        * $k=2$: 至少 75% 数据在均值 $\pm 2$ 标准差内 ($1 - 1/2^2 = 0.75$)。
        * $k=3$: 至少 89% 数据在均值 $\pm 3$ 标准差内 ($1 - 1/3^2 \approx 0.89$)。
    * 切比雪夫不等式给出的是一个**保守的估计**（概率的**下限/下界**）。