大家好，这节课呢，我们就进入第八章驾车检验呃，也是让很多人头疼的一个问题。如果之前你学过，或者听老师或者其他人讲过，假设检验，你可能会听到小概率原理，小概率反证法。或者呢，给你讲个故事啊，比如女士品茶的故事，比如呃扔硬币等等，但是呢，我希望大家能够。把这些暂时忘记，因为通过这些作为对假设检验的引入或者启蒙呃，在我看来呢是？还是有很多后患的。呃，其实与区间估计相比呢，假设检验更贴近我们的生活呃，比如你是一家这个超市的老板。水果超市的老板，那你准备向这个供货商买进一些橘子，假设啊，你要买5000斤，但是呢，你对橘子的大小有要求。这5000斤橘子的平均直径要等于七厘米。呃，这一批橘子平均直径大于七也不行，小于七也不行，必须要等于七。那现在我们已知。橘子的直径，它是服从正态分布的，其中呢，方差已知。那现在。供货商把一车橘子送到你门前，然后告诉你就是按照你的要求供的货，那这5000斤橘子的平均直径就是七厘米。那你肯定是要验货的嘛，符合要求你就收下，不符合要求你就退回去，那你可不可以把每个橘子的直径都测一遍，然后计算这一批橘子的平均直径呢？那理论上是可以啊，但是实际当中这样成本太大了，所以一般都是做抽样检测，那假设你随机抽样100个橘子得到的。样本均值。平均直径啊是六点八厘米。那就这就到了，你做决定的时候，依据样本均值六点八，你认为这批橘子的直径？啊，平均直径是不是七厘米？你如果认为是你就收下，你认为不是你就退货。那你舍身处地的想一想，你是不是？有这样两个无奈，第一个就是不管你抽样的结果如何，你都证明不了这一批橘子的平均直径，它是不是七？我们没有办法在这个只有样本数据的情况下做到对总体参数事实清楚，证据确凿，原因就是这批橘子的。直径它本身就有波动啊，它不是每个都是七，它只是要你只是要求平均是七。而我们的抽样呢？具有随机性。呃，即使你抽到的样本均值等于七，你也证明不了这批橘子的直径就是七。那即使你抽到的样本均值，它是六，你也证明不了这批橘子的直径，它就不是七。这是第一个无奈，那第二个无奈呢？就是说在这种情况下，你还必须要做决定，那这个时候你可能会意识到。你应该在订货的时候就与供货商提前确定一个验收的流程呃，如果检验结果是怎样啊？我们就认为是符合要求的就收下了。如果检验结果是怎样，我们就认为不符合要求就退回，那我们的假设检验就是在确定一个这样的验收流程啊，并且按照验收流程去做决策。在假设检验当中，假设呢，是针对总体的假设。或者是总体参数。或者是总体分布的假设，在我们这一章当中呢，是对总体参数的假设检验。在我们这个例子当中，橘子呢？这一批橘子是总体，而我们关注的参数呢？是总体均值，所以代估参数啊，检验参数是这个。缪那么。检验呢，因为我们手里就只有样本，那就是用样本讯息去检验总体均值。那在我们没有办法，没有办法直接证明总体均值是不是七的时候呢？我们先假设供货商的说法呢，是正确的总体均值就等于七。我们把这个假设呢称为圆假设。或者称为零假设。与缪等于七对立的情况就是缪不等于七，那么这个假设呢？我们即为h1称为贝泽假设。被则假设就是在我们不相信原假设的时候，已被选择的那个假设，那我们先假设h0是成立的，就意味着MU=7。那么u=7。橘子的直径服从的这个正态分布其实就确定了，就是这样一个分布啊，因为这个sigma还是已知的。x8呢，自然也就服从正态分布对x8进行标准化，就会得到一个服从标准正态分布的。随机变量，那么这个随机变量呢？其实它也是样本统计量，在假设检验当中，我们叫做检验统计量。检验统计量，那么检检验统计量，它它在测度什么？或者说它在检验什么，它其实是在测度，在检验样本与原假设之间的冲突。为什么呢？我们来看一下这个z它的结构，它的分子上是x8-7分，母上呢是sigma比上根号n。那么sigma是已知的n呢？在一次。具体的假设检验当中，具体的抽样当中n呢，也是一个确定的数字。所以呢，分母它是一个确定的数字，而且这个分母它一定是大于零的。我们看分子。分子呢x8来源于样本。七呢七呢，来源于原假设啊，因为我们在原假设成立的条件下得到了这个总计量。那所以z如果变化。其实就是分子在变化，那么分子呢？是样样本均值x8与假定的总体均值七之间的差异。它就体现的是样本与原假设之间的冲突。z的变化就意味着样本与原假设之间的冲突在变化。那如果z现在从中心往右走，它意味着什么呢？因为这个是标准状态分布，所以呢？它的中心是零。z从零开始变大，意味着x8大于七。且远离洗。那这意是不是意味着样本与这个原假设之间的冲突在变大呢？如果z它从中心开始往左走，那么意味着x8是小于七的，并且远离七。那这样一个运动方向也体现了原假设样本与原假设之间的冲突在变大。那么，综合起来看，也就是说，在z的绝对值。呃，变大的时候意味着样本与原假设之间的冲突在变大，可是呢，不管这个冲突有多大，不管z的绝对值有多大。我们都没有办法从根本上去推翻原假设，因为这个分布本身就是在原假设成立的条件下得到的。但是呢，我们又要做决策，肯定不能眼睁睁的看着z是z的绝对值一路变大，眼睁睁的看着样本与原假设之间的冲突越来越大而无动于衷，对吧？按照我们很朴素的想法，就是在z的绝对值变大的路上，给它设定一个临界值c。当这个绝对值大于等于c的时候。我们就认为，原样样本与原假设之间的冲突大到一定程度了。我们就选择不相信原假设，那么当这个绝对值小于c的时候呢？我们就选择相信原假设。在假设检验当中，我们选择不相信原假设被称为拒绝原假设。如果我们相信原假设呢，那就称为不拒绝。但是这个新的问题出现了，我们这个cz大于z的绝对值，大于等于c。比如说我们把c。挂到这里。与它对称的呢，是负cz的绝对值大于等于c就意味着。z大于等于c或者z小于等于负c。但是现在新的问题就是临界值，这个c该如何去确定？我们也没有什么呃可以依据的原理啊，什么定理啊，性质啊，去直接确定这个c。呃，统计学家的解决办法呢？是用概率去控制c，那么因为z呢？它说到底它是一个随机变量。z大于等于c这个事情，它是个随机的事情，随机事件它自然就有成立的概率。那我们把它成立的概率呢记为。阿尔法现在的思路就是我们先确定阿尔法，然后由阿尔法去确定。c阿尔法如果变化呢？c就会发生变化。那可是又有一个新的问题，这个概率该如何去确定？答案呢，是人为确定，而且呢，是提前确定。阿尔法在假设检验当中被称为显著性水平。显著性水平啊，碰到具体的题目都会先给我们这个显著性水平的值啊，就跟这个求直线区间都会先给我们直线水平是一样的。那我们在图上呢，再把这个阿尔法和c呢标记一下。我们说这个不等式成立，有可能是这种情况，也有可能是这种情况，那么这两种情况。他们的概率之和。等于阿尔法。那么，又因为这个，它是标准正在分布，所以这个c和负c，它是对称点，而这个减震统计量小于负c的概率。和大于c的概率又是相等的，所以呢，这个两侧尾巴上的面积之和就等于阿尔法。而且呢，两侧尾巴的面积相等。所以右侧尾巴面积是二分之阿尔法，左侧尾巴面积呢也是二分之阿尔法，它们就把阿尔法平分了。那么，由这个分位数的知识，我们可以知道c其实就是z2分之阿尔法。而负c呢，就是负z。二分之二放。那我们如果显著性水平发生变化，那么这两个分位数啊，它一定也会跟着变化的。那在数轴上就形成了这个两个区域，一个区域呢，是这个事件成立的区域。就是从负无穷到。负z2分之阿尔法这一块。遗迹。从z2分之阿尔法到正无穷这一块。好，那么这两块我们称为拒绝域。那中间呢？中间这部分我们称为非拒绝语。非拒绝欲也就是。再进行一次具体的抽样，根据样本计算，得到一个具体的z值啊，具体的z值这个z值怎么来的呢？具体的一个z值，我们写成小z啊，它等于一个具体的样本均值减去七。比上sigma，比上根号n。比如啊，我们假设现在显著性水平，阿尔法等于零点一，我们现在进行随机抽样。样本量n=100。那么总体方差。我们就假定它等于一。那根据这个显著性水平，我们可以确定临界值是多少呢？我们把这个没用的就擦掉了。显著性水平等于零点一，那么它右边的这个临界值z。二分之阿尔法等于z零点零五=1点六四。那么，负z2分之阿尔法等于？负的一点。六四那我们抽样的结果x8。等于六点八，那我们可以依据样本的结果计算一个具体的z值出来。它等于。x8-7比上。sigma现在等于一，然后比上根号nn=100根号n=10。等于六点八减七比上。零点一那就等于。二所以我们根据一个具体的抽样计算得到的检验统计量的值z等于。二然后我们就看这个二它落在哪里，它如果落到了拒绝域，那么我们依据这批样本做出的决策就是拒绝原假设。如果它落在了非拒绝域，那么我们根据这批样本做的决策呢？就是不拒绝原假设。我们看二因为临界值是一点六四和负一点六四，也就是说。这个地方一点六四负的这个地方一点六四，那我们看它是不是落在了这边？好，那它落在了拒绝域，我们就拒绝原假设。那现在呢？虽然呃呃，这个显著性水平阿尔法我取的是零点一啊。是一个小概率，但是呢，到目前为止，我们并没有提到阿尔法是小概率的必要性。所以如果我们现在只考虑做决策，阿尔法并不一定非要是个小概率啊，现在这个阿尔法它只不过是用来控制临界值的。你现在让阿尔法等于零点五零点七都可以，都可以帮助我们把这个决策做出来。呃，不好意思啊，刚才这个地方啊，它不是等于二啊，它等于负二。负二啊，它没有落在右边啊，它落在了左边的拒绝域，那我们同样还是拒绝原假设，那我们现在回过头看一下这个决策的规则，我们首先建立两个假设。原假设和被责假设。好，然后在原假设成立的条件下，我们得到了一个检验统计量，它有明确的分布。这个检验统计量的取值体现了一样本与原假设之间的冲突，那么最后在检验统计量的取值范围上。我们在背离原假设的方向上，选择一部分取值作为拒绝域。那么，从背离原假设的方向上选择一部分，自然就是选择了与原假设冲突最严重的那一部分的统计量的取值。作为拒绝域。那么，冲突最严重的那一部分用阿尔法？来定义，来控制。比如阿尔法等于零点三，那就意味着选择了与原假设冲突最严重的那30%。对应的取值范围作为拒绝语，那么在图上呢？就是两边尾巴的面积各自15%。零点一五。零点一五。那么，对应的统计量的取值范围？这边和这边就作为拒绝域，那么临界值呢？是由阿尔法。来确定的。这个地方如果阿尔法等于零点三，那么这个地方就是z零点一五，这个地方就是负z零点一五。呃，然后呢？我们把这个拒绝域和非拒绝域划定了以后。当我们进行某次具体的抽样的时候，我们可以依据一个具体的样本计算，得到一个具体的。检验统计量的值。我们就看这个值。x8-7比上sigma比上根号n，那么针对一次具体的抽样，我们可以计算一个具体的值。我们看这个具体的统计量的值，它会落在哪里？它如果落在了中间，非拒绝于我们，就不拒绝原假设它如果落在了这边。或者落在了这边的拒绝域，我们就拒绝原假设，那么由于此时拒绝域在检验统计量分布的两侧，那这种检验呢？被称为。双色检验。现在我们来看一下单侧检验，首先来看右侧检验，假如现在我们喜欢小橘子了，那我们跟供货商提要求说下一批橘子的平均直径。不要超过七厘米，那就是小于等于七，那现在供货商又送来一车橘子，告诉我们说就是符合要求的。这是橘子的平均直径呢，不超过七厘米，按照我们刚才的逻辑，应该如何去建立一个决策规则呢？首先呢，还是要建立两个假设，原假设和被则假设。原假设呢，就是供货商的说法，也是我们的要求，与它对立的假设呢，叫做贝泽假设那么小于等于七的对立面，自然就是大于七。啊，这是两个假设，那么接下来呢？我们在原假设成立的条件下呢？去找到一个检验统计量的分布。那么，在这个双侧检验当中，原假设呢？就只有等于啊，它没有小于等于，但是在我们这个右侧检验当中h0，它成了一个。不等式啊，它不它不是单纯的等于七，它是小于等于七，那么我们在找这个检验统计量以及它的分布的时候呢？是在原假设当中。等号成立的情况下去确定检验统计量的分布，那至于这个原因，我们呃后面还会讲。当我们得到这个检验统计量以后，它有明确的分布，是标准的分布，而且它的。取值的变化也体现样本与原假设之间的冲突，那我们想找冲突最大的那一部分。那冲突最大那一部分在哪里呢？在背离圆假设的方向上，那么哪个方向是背离圆假设的方向呢？我们看。在这样一个这个统计量的值的变化过程当中，如果x8。大于七。且远离起。那就意味着这个。样本与原假设的冲突越来越大，因为我们抽到的样本是x8。而缪是小于等于七的，那么如果它是大于等于七且远离七，就意味着与原假设的。冲突在变大，那么具体到这个z统计量上，它应该如何变化呢？x8大于七且远离七，那就意味着。z应该是从中心往右走啊，右边才是冲突越来越大的方向，那么冲突最大的那一部分在哪里呢？在右侧尾巴上。而这一部分我们。它到底是多大啊？我们用阿尔法来控制呃是显著性水平。也就是说，在这个时候右右尾啊，单尾的面积是阿尔法，它往左它如果往左边走。啊，它如果往左边走，那就意味着x8小于七，而且远于七，那是那跟原假设之间的中度呢它。是越来越小的啊，所以左边它不是冲突的最严重那一部分，最右边才是冲突最严重那一部分。如果阿尔法等于零点二。那么这个位置。根据分位数的定义，它是z阿尔法就等于z零点二，而由显著性水平阿尔法。覆盖的这一部分取值范围，那就构成了拒绝域，那么拒绝域现在是。z阿尔法，到正无穷。那下面如果我们进行一次具体的抽样计算，得到一个具体的检验统计量的值。好，这个时候我们看这个值，它是落在了这里，还是落在了这里？它如果落到落在了这个。拒绝域，我们就拒绝原原原假设如果它没有落到拒绝域，落到了非拒绝域，我们就不拒绝原假设或者根据我们这样一个具体的值，我们把它写成。小z去与这个z阿尔法做比较。它如果大于z阿尔法，就意味着它落入了拒绝域，我们就拒绝。如果啊，大于等于如果z是小于z阿尔法。我们就不拒绝，因为它落在了非拒绝域。那这个就是右侧检验啊，这是单侧检验的其中一种，那么另外一种呢是呃左侧检验。我们接下来看一下左侧检验。那假设现在我们喜欢大橘子了，我们对供货商的要求是说橘子的直径，平均直径要。大于等于七呃，那么在大于等于七的情况下要求之下呃，供货商又给我们送来了一车橘子呃，告诉我们就是符合要求的。我们刚才的逻辑再重复一遍，首先就是建立两个假设，那么原假设就是供货商的说法，也是我们的要求。与它的对立面就是MU小于七，那么我们还是在h0中啊，等号成立的条件下。去确定检验统计量的分布。以及依据这个检验统计量呢，去计算一个具体的样本的统计量的值啊。那我们得到这样一个分布，得到一个这样的统计量之后，它的曲值的变化仍然在体现样本与原假设之间的冲突。我们还是希望在下面这个分布当中。找到冲突最大的那一部分，那冲突最大那一部分在哪里啊？在背离原假设的方向上，那么在这个时候。当。x8。小于七啊，且远离七的时候。也就是z从中心开始往左走的时候。才能够体现样本与原假设的冲突越来越大，那么最左边就是冲突最大的那一部分。那冲突最大那一部分，我们用显著性水平阿尔法来控制，也就是说在左尾上我们。切走一个阿尔法，这就是冲突最大的那一部分啊，阿尔法。覆盖的z的取值啊，就是冲突最大的那一部分，那这一部分。就是我们的。拒绝于啊。那这个分位点。他是谁呢？他是z。负z阿尔法。所以现在的拒绝域是负无穷到负z阿尔法。那如果现在我们得到了一个具体的样本。计算一个具体的样本的检验统计量的值，然后。看这个值是落在了拒绝域，还是落在非拒绝域？落在拒绝域，我们就拒绝落在非拒绝域，我们就不拒绝。啊，这个拒绝和不拒绝都是针对h0而言的啊。那好嗯，我们在做双色检验的时候呢呃，用到一个一组数据说是样本量n=100。然后计算的样本均值x8=6点八啊，现在我们规定显入进水平，阿尔法等于。零点零五。好，那么现在我们根据。这个检验统计量的公式，把这样一个具体的样本的检验统计量的值计算出来，那就是。六点八减七比上sigma还是假定是一啊，比上根号n根号一百是十。那这个结果呢？是负二，而我们的显著性水平，阿尔法是零点零五对应的临界值是负。z零点零五是负的一点六四。那在这个时候我们看。负二。是不是落在了这样一个区间呢？这是负一点六四，那它落在了。拒绝欲或者我们。把这个具体的。样本统计量值z和负z阿尔法临界值做比较，如果它是小于等于临界值，我们就拒绝原假设，那么这个时候。负二小于等于负一点六四啊小于。负一点六四那么。同样的也是拒绝原假设。矩形假设就意味着我们认为橘子的平均直径啊，不是大于等于七。当然了，这个是我们依据这样一个样本得到的一个决策，如果换一个样本呢，未必就是这样的决策了。那刚才呢？我们讲了假设检验的几种情况，双侧检验，双侧检验的原假设呢？是等于。等于号那么它的拒绝率在两侧啊，在这个检验统计量分布的两侧，所以呢，它被称为双侧检验。而在右侧检验当中，原假设是小于等于号，它的拒绝域呢？分布在。检验统计量的右侧，所以它是右侧检验，那么左侧检验呢？就是原假设它是大于等于。那么，它的拒绝率在检验统计量的左侧啊，我们称为左侧检验，那不管是哪一种检验？呃，其中很关键的一个步骤就是在原假设成立的条件下，找到一个检验统计量，它有明确的分布，而且我们也可以通过。这个井印统计量的构造。去求得一个具体样本的检验统计量的值，那么在检验统计量的变化范围内。我们找到一个与圆假设冲突的最大的一部分，取值作为拒绝域，那么最大的一部分呢？由阿尔法控制。阿尔法确定了，那么它覆盖的密这个检验统计量的取值范围也就确定了，那么这个取值范围就是拒绝率。呃，取值范围的端点就是零件值，那么最后呢？我们根据具体的抽样计算得到的。检验统计量的值与临界值去做比较。呃，从而做出决策，可是呢，我们不管是拒绝原假设还是不拒绝原假设，其实都没有从根本上。去证明什么？那么我们做的决定一定是正确的吗？那显然是不一定的啊，我们希望能够以小见大。但是呢，难免以偏概全，下面我们就看一下假设检验中可能出现的两种错误。以及显著性水平，阿尔法是小概率的原因。下面呢，我们就通过一个右侧检验来说明呃，两类错误的问题，这个是我们的大前提啊，总体服从正态分布，并且。方差是已知的，那么这个是原假设和贝塔假设我们在原假设当中等号成立的条件下来确定。检验统计量以及它的分布，并且依据检验统计量的构造可以得到一个具体的样本的检验统计量的值。那么，我们通过。显著性水平，阿尔法啊可以控制这个。临界值那么当。检验统计量的具体的值比zr发大的时候，就意味着它落入了拒绝域，我们就拒绝原假设那么。里边这个不等式。其实表示的就是右侧检验的拒绝域，我们把这个。不等式做一个等价变换，变成一个x8。大于某一个数字，这样一个概率，那么由于不等式是等价的，所以它们的概率呢，一定也是相等的，也是阿尔法。那么实际上呢，我们就把这个在标准状态分布当中。那去看待这个问题，转换成了在x8自己的分布当中去看待这个问题，那么x8大于等于。这样一个数字，实际上就是这个检验问题。在x8自己分布上的一个拒绝域啊，如果大于这个值，我们就。x8如果大于这个值，我们就拒绝了。原假设啊，因为不等式等价，所以这个概率一定也是阿尔法。那么，我们把检验问题转化到x8自己的分布上来之后，呃，我们再看一下这个。嗯，两类错误啊，它的定义是什么？那么这里面有两条密度曲线，它其实都是x拔的分布。那只不过上面这一条是h0成立。啊是h0成立的时候。x8的分布。那下面这条呢，是h0不成立。h0成立就是小于等于7h零不成立，那就是大于等于七啊，那它具体等于多少我们不管，反正它在。反正这个当h0不成立的时候，这个密度曲线它更偏右就对了，那么这个曲线呢是h0成立啊，是等号成立的时候我们确定的。呃x8的分布。那这条红色的虚线呢，是我们确定的临界值的位置，那么按照。这个等式。啊，按照这个等式，那么右边的概率呢？一定是。阿尔法一定是阿尔法，那么这个值啊，就是我们从这等价变换得到来的这个值啊，这个值就是在x8分布当中。解决检验问题的临界值。好，那么在这个呃红线的左边，我们的决策是什么？啊，是不拒绝原假设。那么，到红线的右边呢？我们就拒绝。云，假设。那这是我们的决策规则，那么原原假设是不是成立就这两种情况？它是不是成立？它其实是个客观的结果。它要不已经成立了，它要不已经不成立了，只是我们不知道而已啊，就像这批橘子的直径，它要么已经小于等于七了，要么已经大于七了。他这客观情况其实已经二选一确定了，但是我们并不知道哪个假设是真的。而我们做的决策，拒绝不拒绝或者拒绝，它是依赖于抽样结果的，而抽样结果具有随机性，所以我们的决策也是具有随机性的。那么，在原假设成立的条件下，我们不拒绝原假设，那也就是。没有犯错误啊，是正确的决定，那假设成立，我们不拒绝，那这就是正确的决定，如果。原假设成立，我们拒绝了，那就是犯了错误。那这种错误呢？我们称为细针错误。或者称为异性错误。异性错误，那么这概这个错误发生的概率是多少呢？恰好就是阿尔法。恰好就是阿尔法啊，那因为我们在原假设成立的条件下，拒绝原假设的概率就是阿尔法。而器针错误描述的恰好就是原假设成立的条件下，你拒绝了原假设。那所以我们把这个概率写一下p=h零成立的条件下，我们拒绝了原假设。它等于阿尔法，那么这个是细针错误或者一型错误的概率，就是阿尔法，那么在这里如果说h0成立，我们不拒绝这样的概率，恰好就是一减阿尔法。阿尔法，这是h0成立情况下，那么h0如果不成立啊，我们没有拒绝原假设。它不它不成立，我们没有拒绝，那就犯了错误，那这个错误呢，叫做虚伪的错误。它的概率是多大呢？h0不成立的时候x8的分布是这样的，是下面这条偏右的这一条，那么在h0不成立，我们又。没拒绝，就意味着取值的取值。在这个红色期曲线的左边，那么它对应的概率呢？啊，就是蓝色的这一部分，我们记为贝塔。就一杯汤。这个区域的错误，我们也可以称为。二型错误。这个是犯二型错误的概率，那么最后一种情况，当h0不成立。我们拒绝来吃零。h0不成立，我们拒绝了h0，那当然是没有犯错误，那这个概率呢？是一减贝塔。那么，我们实际上就构成了一个二×2的情况。由h0分成两类成立和不成立，由我们的角色分成两类，不拒绝和拒绝，那就二乘二四种情况，那么在这两种情在这四种情况当中。有两种情况下是犯了错误，一个是h0成立的条件下。我们拒绝来吃零这种错误叫做细针或者一型错误，它的概率是阿尔法。那么，另外一种在h0成立的条件下，我们不拒绝原假设就犯了错误。啊，这个作用的概率我们记为贝塔。那么，另外一种不犯错误是一键回答，那这就是二二乘二四种情况，那我们重点关注的呢？是两类错误。那对于犯错这种不好的东西，我们肯定是希望让它越小越好，但是在样本量确定的情况下，阿尔法和贝塔。有没有可能同时变小呢？嗯，在样本样本量确定的情况下，意味着这个呃分布，它就是明确的了哦，它的这个高矮胖瘦都确定了。那在这个时候，阿尔法和贝塔可不可以同时变小？我们当然是，可是这个希望它能同时变小，但是事实上，如果阿尔法变大。那么，意味着这条红线就会往左移，这条红线往左移就会引起白色的变小。那如果阿尔法变小。意味着这条红线要往右移，红线右移啊，意味着白塔会变大。所以我们看阿尔法和贝塔，它其实是一个此消彼长的关系，我们不可能同时让它变小，也不可能啊，让一个变小，另外一个保持不变。啊，所以在这种情况下，同时减少两类错误的想法呢，就没有办法实现了。那这个就像在电视剧里演的，这个医生问你保大还是保小，同时保已经保不了了，这种情况当然是。哪一个更重要？我我就保哪个那比如说我认为大的重要啊，我保大那有人就认为小的重要就保小。那每个人看中的东西不一样，没有关系，那这是一个个人的决策，但是在检假设检验当中。啊，由于这个阿尔法和贝塔，它是此消彼长的关系。我们必须要选择一个啊，那么在假设建议当中选择的是哪个呢？选择的是控制阿尔法。控制阿尔法，控制阿尔法的意思就是让阿尔法变小。啊，让阿尔法变小。为什么我们选择去控制这个阿尔法呢？为什么要让阿尔法变小呢？一个是因为我们需要一个统一的规则啊，必须要。有一个统一的规则，我们在这个不同的人在做假设检验的时候讨论交流都比较方便啊。另外一方面呢，原假设它比贝泽假设更加的精细，贝泽假设呢，相对更模糊一点儿，比如在这个双侧检验当中。h0。它是缪等于缪零，缪零是某个常数，而h1b则假设它是不等于那么不等于这个范围，可就大了，对吧？所以说呢？原假设比贝德假设相对来说，它更加明确，我们知道它说的是什么啊？背的假设呢，就比较模糊啊，基于两以上两个原因啊，也就是说一个我们要统一的规则，第二个呢？原假设呢，更加的清晰，所以我们选择了控制阿尔法控制器针错误的概率啊，就是让阿尔法尽量的小。那么，这个阿尔法。多小才算小呢，一般情况下常用的阿尔法，常用的显示器水平有三个零点一。零点零五零点零一这三个当中最常用的是零点零五。好，那么对于这个呃什么临界值临界值，实质上它是分位数啊，那么对于常用的分位数，尤其在标准正态分布情况下的。常用的分数，希望大家可以记忆一下啊好。呃，我们这里提醒大家一下，就是这个阿尔法，它是在原假设成立时拒绝原假设的概率是一型错误或者细针错误的概率。它并不是原假设不成立的概率啊。原假设是否成立，它是个客观既定的事实，只不过我们不知道而已啊，我们不能用。这个阿尔法去表示，原假设是否成立的概率。这个大家要注意一下呃，很多人在理解的时候，他认为阿尔法它是一个很小的概率，如果这个很小的概率发生了，就意味着这个。原假设成立的概率很小啊，其实这不是一个正确的逻辑啊，阿尔法的值和原假设成立。啊，没有关系啊，就是说你不能通过阿尔法去反退原假设是不是成立啊？那到现在为止呢？我们不但能够做决策嗯，还知道显著性水平。阿尔法是一个小概率。那因为呃阿尔法呃，它是一个小概率在我们这个决策规则之下呢，原假设事实上就处在一个被保护的地位上。我们不轻易拒绝原假设呃，我们只是在这个呃，与原假设冲突的。呃，最严重的那一部分，让取一个拒绝域，而且呢，这个最严重的部分，我们还给它取了一个小概率。所以呢，这个是不轻易拒绝原假设呃，但是这个不轻易拒绝呢，它是战术上的，不是战略上的。从更高的维度看，我们可能想的就是要推翻原假设，但是在具体执行决策流程的时候呢？我们就要谨慎，不轻易拒绝，那么在不轻易拒绝原假设的背景之下，如果我们还拒绝了原假设。那就更能说明原假设啊，它太可疑了，这也是我们在单测检验当中啊，取原假设中等号成立的条件下。去构造检验统计量原因，比如说。我们之前讲过的啊，这个左侧检验当中，那我们这个检验统计量的构造以及一个具体的样本。计算得来的检验统计量的值都是在原假设中等号成立的条件下去做的。那么这个时候如果我们不取等号成立，那么你不取等号成立，它是大于等于g，你要取一个大于七的数字，对吧？比如现在我们从大于七的一个数字里选择了九。选择了九，我们看会发生什么x8-9比上sigma比上根号n，那么这个如果它作为一个检验统计量的话，它。它是不是还服从标准正态分布呢？是的啊，它的分布是不会变的啊，还是服从标准正态分布，那么临界值会不会变化呢？不会因为这个分布没有变化，临界值是。不会发生变化的。那什么是会变的呢？就是一个具体的样本计算得来的，统计量的值是会发生变化的，它会如何发生变化？啊，我们把这个MU 0u7换到九的时候，这个检验统计量到的值，它会变小。比如还是刚才的六点八，我们代进去之后，它会变小六点八。减九哦，那这个就是20多了吧？啊负20多，那它会变小，那么在一个左侧检验当中，如果一个具体的样本。的检验统计量的值它变小了。那它意味着什么？意味着它更倾向于拒绝原射啊，因为这个。临界值啊，它是一个负的，如果检验统计量的值倾向于变小，那它倾向于往左走。倾向于往左走，意味着倾向于落入拒绝域啊，所以如果说我们在不选等号成立，选择一个更大的数字的时候。我们就倾向于拒绝原假设了，而在我们决策流程上，是我们其实倾向于保护原假设不轻易拒绝原假设。所以我们选择在原假设。大于等于七啊，它是呃七到正无穷啊，所以我们选择它在端点处的这个值啊。成立的时候去构造检验统计量计算具体样本的检验统计量的值才能才能体现我们对呃原假设的保护，要不然的话。如果这个值啊，如果在大于等于七的这个范围内，我们可以可以任意选择一个值的话。你选择九，你还可以选择个十，那你只要选择了这个数字足够的大，那么它的拒绝假设。的可能性就会越来越大啊，这个跟我们这个保护源假设的原则呢，是相违背的。这就是为什么我们在单次检验当中，我们选择等号成立的条件下。进行下一步的检验。那我们再回来。那我们在这个做决策的过程当中，最后一个步骤其实就是一个比较的过程比较。计算这个通过具体抽样计算得来的样本统计量的值和。临界值啊，它俩做比较，从而做出决策，那这种方法呢，叫做临界值法，还有一种方法呢，叫做p值法。我们来看一下什么是p值啊？p值也是一个让很多人迷迷糊糊的一个概念。首先我们来看右侧检验，那么在右侧检验当中呢？原假设是缪小于等于缪零啊，缪零呢，它是一个常数啊，这个常数到底等于几？需要看具体的情况来确定了。那么，当原假设成立的时候呢？检验统计量，它是服从标准正态分布的。普通标准状态分布那么显著性水平，是阿尔法那么这个时候呃，我们这要选择一个。与原假设啊，冲突最大的一部分作为拒绝域，也就是在。背离原假设的方向上，也就是右边啊。滑走阿尔法那么对应的临界值，是z阿尔法对应的拒绝率，是z阿尔法到。正无穷那么小z是我们通过一次具体的抽样计算得来的一个具体的检验统计量的值。那么，我们用小z和临界值做比较，如果小z大于等于z阿尔法，假设它就落在了。这个位置它是大于等于z阿尔法落入了拒绝域，那我们当然就拒绝原假设。句绝假设，此时那我们在做一件事情，如果我们以小z在这里啊，小z为起点。做一个累积概率的事情，往哪累积呢？往这个背离原假设的方向上，也就是右边做一个累积概率。那么这个概率。实际上就是。检验统计量z大于等于小z的概率，那么这个概率与阿尔法相比。啊，它一定是小于阿尔法的。一定是小于阿尔法，也就是说，如果z落入了拒绝域，我们求一个z大于等于小z的概率。那么，这个概率一定是小于等于阿尔法的啊，因为我们在它的右边，还向右边累积。啊，那这个概率。一定小于阿尔法，那如果z大z小于z阿尔法，也就是它落入了这个。非拒绝语，比如说它就在这儿，那么我们按同样的方法还是从z开始。累积概率的方向还是一样的，还是往右往背离圆假设的方向上去累积，那么这个概率一累积就一定是大于阿尔法的。一定是大于阿尔法。那我们当z小于z阿尔法的时候，我们是不拒绝原假设的。不去晕车的，就这个时候我们。可以发现，现在我们可以直接用这个概率。与阿尔法做比较。呃，这个概率小于等于阿尔法，我们就拒绝假设那么大于。显示显示性水平，阿尔法我们就不拒绝原假设，那么如果我们用这种方式去做决策，我们多了一个。求概率的步骤啊，求这个概率的步骤，但是省去了。求这个临界值，或者是查临界值表的这样一个步骤啊，因为我们如果从这个地方。求概率啊。我们不需要临界值，对吧？但是呢，我多了一个求概率的步骤。那这个概率就是p值。这个概率。这个概率。这概率这概率就是p值，那么它的含义是什么？是当原假设。成立时，样本观察结果或者更极端的结果。或者更极端的结果出现的概率。那么，这是一个什么样的含义呢啊？样本观察结果我们知道啊，就是根据。这个样本统计量计根据一个具体的样本计算的，一个具体的样本统计量的值啊，这就是样本。观察结果那么这个样本观察结果，它可以落在这个数轴上的任何一点。啊，它的取值范围就在这个整个数轴上，它可以落在任何一点，这个没有问题，那么什么叫做更极端的结果呢？这个极端，它其实体现的。含义就是要背离原假设。啊，背离原假设那比样本观察结果更极端，那也就是要在样本观察结果的基础上。往更极端的方向走，往背离原假设的方向上走，比如。我们现在取到了一个小z。是这里啊，根据一个特定的样本计算，它的样本观测结果就在这里，那么比它更极端的结果在哪里啊？对于右侧检验来说，对于原假设是小于等于号来说，更极端的方向就是。更加背离原假设的方向，它就在右边，它就要往右边走，那么更极端的结果就是。再去这个小z右边的所有的值都比这个z要更加极端，那么。样本观察结果z和更极端的结果发生的概率其实就是从z开始。往右边累积概率。啊，往右边累积概率，这个就是p值。p值那显著性水平是提前给定的，它跟这个样本没有关系，而p值呢？就是依据具体的抽样结果得到的一个概率啊，那么作为右侧检验的p值就是从我们得到的。让门统加上的值往右累积概率，他不管。落到哪里你都要往右累积它，如果落在了非拒绝域。我们往右累积的概率一定是大于阿尔法，那这个时候我们就不拒绝假设，那么如果我们计算得来的样本统计量值，它落入了拒绝域。我们从这开始累积概率，那么我们得到的这个p值呢？就一定是小于阿尔法，小于等于阿尔法。我们就。拒绝原假设。那在这个左侧检验当中呢？不论这个具体的样本，统计量的值它落在了哪里？都要从这个值值开始，从小z开始往左累积概率。才是我们需要的p值。啊，往左累积。才会得到p值，因为在左侧检验当中。原假设是大于等于缪零，那么与原假设背道而驰的方向就在左边，与原假设冲突更大的方向就在左边。好，那么我所以呢，我们通过一个具体的样本，得到一个具体的样本统计量的值的时候。就要从这个值开始往左累积概率，往这个背离圆假设的方向上累积。那么，与右侧检验这个是一样的，如果这个p值小于等于阿尔法，就意味着我们的。这个样本得来的统计量的值。落在了拒绝域啊，落在了拒绝域的话，往左累积概率，这个p值一定是小于等于阿尔法。我们就。拒绝原假设。如果这个p值是大于阿尔法的，那么它同它也意味着这个z落入了非拒绝域，我们就。不拒绝演讲社。但是现在我们这个品质的，具体的表示的方式。是检验总计量小于等于一个具体的样本观察结果。也就是检验统计量的值的概率啊，所以左侧检验就是小于等于z的概率是p值。而右侧检验呢，是大于等于z它们这个。取值范围可能是一样的，但是它的累积方向是不一样的，右侧检验就要从具体的值往右侧去。累积左侧检验呢，就要从一个具体的值。往左侧开始累积概率，那么判断的规则呢？也是跟右侧检验是一样的，就看p值和阿尔法的比较。小于等于就拒绝。大鱼就不拒绝。好，这个是左侧检验的p值，我们来看双侧检验的p值。那在双侧检验当中p值呢？就有点不一样了，因为在双侧检验当中左右都是背离圆假设的方向。那我们的样本统计量的值，比如它落到了这里，那么左右都是被列为假设，那我们总不能往左和往右同时累积概率吧？那这样的话呢，累积完的这个概率一定等于一啊，你从一个点开始往左往右那。就是这条曲线下的全部面积，它一定等于一了啊，那它显然不是这样的，我们看这个p值的。定义啊p值，它是一个概率，那它针对的事件呢？是样本观察结果或者更极端的结果。那么，从极端性上来讲。比如我们现在抽到了一个点啊，它落在了这个位置。那么，我们从极端性上来讲。它关于零的对称点，那这两个点z啊负z它是同样极端的。啊，它是同样极端的，这两个结果同样极端，那么比他们更极端的结果在哪里呢？就是从左边这个点往左。是比负z更极端，从z开始往右。累积。那么，它右边的取值是比z更极端。那么，这两边的概率之和啊，也就是这两边的面积之和合起来。才是双侧检验的皮脂。所以我们发现这个。呃，单侧检验当中往p值。是往一个方向累积概率，而双侧检验当中呢，要找到。这个样本统计量的值以及它的对称点。那么，它就是只有两个值，那么一定是一个正值和一个负值。从负值开始往左累积。加上从正值开始往右累积，这两个概率合起来是p值。你如果抽到了点。本身是个负的，操作起来也是一样的，也要找到它的对称点。啊，反正是一正一负负的往左累积，加上正的往右累积。双尾之和等皮质。那这就是双侧检验的p值呃，同样的，如果p值是小于阿尔法了，那就意味着。这个我们的具体的样本统计量的值一定落在了拒绝域，才会才会在两边累积出来的概率。是小于阿尔法的啊，如果我们的这个具体的样本统计量的值落在了。非拒绝意义。那么，这两边累积起来的p值呢？一定是大于阿尔法的，所以我们也可以用同样的。方式p值小于等于阿尔法，我们就拒绝。p值大于阿尔法，我们就不拒绝。那这三种情况下的p值呢？我们就讲完了嗯，大家呢？要注意在不同的呃检验当中，双侧左侧和右侧。他们的累积方向是不一样的。在双色检验中呢呃，还是像这个有两个对称点，分别向两边累积在。左侧检验当中啊，它向左累积，所以这个是小于等于的概率在右侧检验当中，它是。向右累积啊，所以它是一个大于等于的概率。那三种情况下的p值，我们讲完了，提醒大家注意的是这个p值啊，它不是原假设不成立的概率。也不是被则假设成立的概率，原假设与被则假设哪个成立哪个不成立，这是一个确定的。但是未知的客观存在，而p值是什么呢？p值它是一个依赖于抽样结果的概率，那一个总体的特征是否成立？肯定不会依赖于抽样的结果的，对吧？那你如果说你抽一个样本。p值是呃零点三，那肯定不能拒绝，假设那我在同样的总体当中也抽同样的样本量。抽出来的这个样本计算得来的p值可能是零点零零二，那我就拒绝原假设了。那我那我们的这两个抽样，结果会影响原假设成立不成立吗？不会的啊，原假设是个确定的客观存在，不会依赖于一个随机结果的。这是第一点，第二点呢，就是我们用p值和显著性水平比较来做决策，和我们用临界值法来做决策，决策结果是等价的。啊，角色结果也是一样的，那p值有什么优点呢？它的优点在于更直观的表现，某一次检验的角色风险。那我们说的这个决策风险呢，就是这个犯一型错误的概率，那比如说在一次检验当中。这个p值，它现在等于零点零零三，那给人的感觉就是啊，即使显著性水平降到零点零零三，这次检验也可以拒绝原假设。那虽然我们提前给定的阿尔法啊，可能就是零点零五，但是呢，我们的p值是零点零零三，我们就认为啊，即使显著性水平。下降到零点零零三。那我们还是可以拒绝假设，那就说明这这一次的决策风险实际上要比给定的阿尔法要小。那如果p值是零点零四九呢？啊p值等于零点零四九，那给我们的感觉就是在阿尔法等于零点零五的显著性水平上，其实是勉强拒绝云假设的。虽然他们都拒绝了原假设在显著性水平啊，等于零点零五的时候，但是。这一次的决策风险。比零点零四九。要小。好，那这个就是我们对于假设检验的呃，基本思想和涉涉涉及到的要素啊，这就介绍完了。包括我们最初面临的无奈，不能证明总体参数的取值到底如何的情况下，还必须要依据样本做决策。在这种无奈之下呢，我们选择了与原假设冲突最大的那一部分，作为拒绝域，那么拒绝域呢，有显著性水平，阿尔法控制。此时的阿尔法，它并不是一个小概率，直到我们介绍了两类错误，并且在两类错误此消彼长的背景之下。选择了控制一型错误的概率，才导致阿尔法是一个小概率，那么最后我们介绍了p值和p值决策方法。那么p值的决策方法和临界值决策方法在疑似抽样的检验当中啊，他们的这个决策的结果是等价的。下面呢，我们通过一个例子走一遍，这个假设检验的流程。我们来看这道例题，说这个某机床厂加工零件，根据经验，我们知道那么这个经验呢？其实就是说的过去的事情，过去怎么样？以前怎么样？以前是该工厂加工零件的椭圆度近似服从正态分布，总体均值等于零点零八一，总体标准差等于零点零二五。现在呢，我们换了一种新的机床进行加工。啊，抽取了n=200个零件呢，进行检验得到的样本均值是零点零七六。那么，现在问新机床加工零件的椭圆度的均值与以前有无限度差异？那么，现在新机床的。椭圆度的均值是我们要检验的参数，也就是总体均值MU与以前有无限度差异，以前是什么情况？以前它的平均值。是零点零八一。问你有没有显著差异？那么差异这种东西是不分方向的啊，小也是差异，大也是差异啊，所以。它是一个双侧检验呃，原假设是等于彼得假设呢？是不等于呃。那么，这个两个假设我们就建立起来了，那么在h0成立的条件下呢？我们要找到一个检验统计量，并且确定它的分布。因为我们这个题目当中啊，并没有给我们提供这个样本标准差的信息，所以呢，我们假定还是用总之前总体的标准差sigma。那也就是正态，总体方差已知的情况了。跟我们之前啊，举例子的都是同样一种情况，所以我们还是用这样一个检验统计量。那么，把sigma还有n啊，还有缪零都带进去，就会得到这样一个统计量，它服从标准，正态分布。那么，这个统计量检验统计量，它有两个作用，一个是它有明确的分布，我们可以在它的分布上去找临界值。现在规定的显著性水平是零点零五。双侧检验当中，临界值z2分之阿尔法等于。z零点零二五=1点九六，那么在双侧检验当中，它右边的临界值啊，就是一点九六。左边的零件值就是负一点九六。这是它的第一个作用。关于临界值，第二个作用呢，是我们可以根据一个具体的样本均值得到一个具体的。检验统计量的值，那就是把零点零七六啊，对这个x8进行替换就可以得到一个具体的值，那等于负的二点八三。剩下的问题呢？就是看。我们计算得到的这个样本的观察结果，也就样本检验同计量的值和临界值的关系是什么？现在。z=- 2点八三，它是小于负一点九六的。小爷负一点九六，就是他落入了拒绝域。所以我们在阿尔法等于零点零五的水平上拒绝了h0，那么这个阿尔法等于零点零五。的水平是什么意思呢？因为我们在确定临界值，确定拒绝域的时候，就是在这个水平上确定的。所以我们做决策也是在这个水平上做的啊，所以在后面写在阿尔法等于零点零五的水平上继续了h0啊。而不是说它在所有的水平上都可以咀嚼，如果我们的显著性水平取一个非常小的值，那现在的这个负二点八三。就未必可以拒绝人家射了，因为阿尔法如果变小的话，那么临界值还会继续往左边走。这边往右边走。那么，临界值就会变得更小，那么这个负二点八三呢？就未必比新的临界值更小了。好，所以呢，这个是这句话的含义啊，他为什么说在这个水平上拒绝那么最后的结论是新机床加工的零件，与以前有显著差异啊，这个就是我们认为有显著差异。这个是我们用呃临界值法做的决策，我们也可以用p值，那么对于p值来说呢？对于一个双侧检验，如果我们的。这个小z是落在了这边嗯。在这里，我们同时找到它的对称点，一左一右，从左边这个点往左边，累计概率从右边这个点往右边，累计概率这个概率之和就是p值。那么，用一个不等式表示就是z的绝对值，这个是检验统计量，它这个随机变量。大于等于小z的绝对值，小z呢，是我们计算的一个具体的结果，那计算。的这个最后的结果呢是零点零零四六五五，那这个结果是小于零点零五的显著性水平的小于阿尔法。那么，在这个情况下，我们同样拒绝云假设啊，用临界值和用p值它的这个呃决策的结果是一样的。