大家好，上一章我们讲解了一元线性回归一元的意思呢，是只有一个自变量，线性是自变量x。与因变量y之间为线性关系，今天呢，我们要学习的是多元线性回归，那么多元的意思呢？就是自变量有多个。那就意味着影响因变量y的因素有多个，那这实际上是实际问题当中更常见的一种情形。呃，比如影响收入，影响个人收入的因素，可能包括学历，年龄呃，
子女数量，所处的行业等等。那这些因素可能对收入的影响是不一样的，也可能会有主次之分，但是呢，我们很难说收入的影响因素是唯一的。呃，比如影响高考成绩的因素啊，那么高考成绩可能会受到个人的因素的影响，比如。呃，智商努力程度，心理因素等等呃，可能会受到家庭的因素的影响，比如父母的学历，
家庭的收入，家庭的。呃，关系兄弟姐妹的数量等等。啊，这就是。多元回归的啊，应应用场景那下面呢，我们来看多元线性回归模型和方程。那y呢，是因变量自变量呢，有k个x1x2到xk。代表k个自变量。那么，前面这个式子啊，
贝塔零还是一样的含义，它是截距，那么前面的这个式子能不能？决定y呢呃，能不能决定一个这个确定的y出来呢？这个是不能的。呃，还要加一个随机误差项，也就是说因变量y会在前面这个确定的关系上。在这个线性函数上加一个随机波动，那这个式子呢？我们就称为多元回归模型。我们同样啊，对误差项这个一手有三个假定。那么，
第一个假定呢？称为零均值啊，这个随机误差，它的数学期望是零。那我们有k的自变量，这个k的自变量在它各自的取值范围内可以任意取值，那么这就这就使得x1到sxk它这个取。咀嚼的组合可能有无穷无尽个，那么这个。一送它的数学期望为零，它的含义就是说不管x1到sk都取什么值。不管x1到sk，它们的取值是怎样组合的？后面的这个误差随机误差的期望都是零。啊，
比如啊，我们这后这个表格当中。有三个自变量，它们有不同的取值，有不同的取值的组合，比如对于这样一个组合，它是不能。完全确定一个歪出来的，还要加一个一种，那么在这个组合后面的一种。他的期望是零，那如果我换一个组合呢，比如说这个组合啊。自变量的取值是给定的，即使我们现在知道贝塔零贝塔一到贝塔k，
我们也不能确定y值。后面还要加一个因素，那么这个因素它的期望也是零啊，这就是零均值的含义，就是不管k的自变量取值如何？后面的随机误差的期望都是零，那么在零均值的假定之下，如果我们对回归模型两边同时求期望。左边就是。y的期望右边呢，前面这个确定性的关系，这个线性函数，它的期望就是它本身。因为贝塔零贝塔一一直到贝塔k，实际上是参数是客观存在的，
只是我们未知而已。啊，它不是随机的，那么x1到sk呢，这个也是固定的，没有随机性。所以前面这个部分的期望就是它本身那后面这个因素的期望呢，就是零。所以我们得到y的期望是后面的这个确定的线性关系。这是第一条假定，第二条假定呢，是同方差就对于自变量x1到sk的。所有值。后面的这个因素的方差都等于西格玛方，那我们不是刚才不是说平均值的含义是不管k的自位量取值如何，
后面的随机误差的期望。啊，都是零。那现在的这个同方差讲的意思就是不管x取值如何呃，不管自变量的取值如何组合，后面的这个随机误差的方差。这个方差sigma方差。呃，移送的方差等于sigma方呃，这个移送它的方差。也是sigma方啊，这个是同方差的含义。那如果现在我们对这个线性模型左右两边同时求方差，左边就是y的方差，右边呢是两个部分。
那么，这两个部分前面啊，我们说了这个线性关系，它是不具有随机性的，它的方差。等于零。那后面呢，逆时针的方差，我们刚刚说过它的方差等于sigma方，那所以y的方差。等于一乘的方差，等于十英瓦方那y的随机性，完全来自。后面这个随机变量。第三条呢，
是正态性且独立。那么，这个独立说明什么呢？就是说我这个。组合之下的这个因素。跟其他任意组合之下的移送都是独立的。都是独立啊，不相关的。那么正态性呢？是说呃，不管x取值如何y呢，都服从正态分布，那这个呢，我们也可以从这个模型中。得出来的。
啊，因为后面这个一种现在呢，我们假定。它服从状态分布。前面是一个确定的，然后后面呢加一个正态。就能导致啊，这个y也服从正态分布。那么，正态分布它的y的期望，我们知道了y的方差，我们就知道也知道了，所以我们知道了y。它浮动正态分布，并且它的这个正态分布的两个参数，
我们也能够确定。那这个就是。呃，关于随机误差运送的三个假定。那现在我们看对这个多元回归模型，两边同时求期望得到的。这个式子啊，它描述了y的期望与自变量之间的线性关系，而且呢，这个线性关系呢？它是确定性的关系。那描述了这个关系呃，这个式子啊，就是称为啊多元回归方程。那我们的目标呢？
其实就是估计这个方程。就是估计这个方程的截距和k个系数呃，就是用样本得到这样的一个。估计的回归方程啊，就是得到截距和系数的。估计值。那么，在一元回归的时候呢？我们学习了最小二乘法。呃，在多元回归对截距和系数的估计还是使用最小二乘法，找到能够使残差平方和最小的。参数估计值。那一元回归的时候呢，我们只需要对截距和一个系数求偏导，
因为一元回归它的估计的方程。等于v0派等。eh at x，它只有一个。自变量那么这个。残差平方和展开这个形式的时候呢，它就只是这个残差平方和就只是关于贝塔0 hat和贝塔1 hat的函数。但是，在多元回归当中，我们把这个残差的平方和展开以后。那我们发现它是贝塔0 hat的函数，那这个是截距它还是k个？自变量系数估计值的函数。这里头有k个，这里头有一个，
所以说我们不但要对。这个beta 0 hat截距的估计值求偏导，让它等于零，我们还需要对k个自变量的。系数估计值逐个求偏导，那我们就会得到k个k+1个。方程构成的方程组。然后呢，去求解这个k+1的参数。那么，在多元回归当中，这个k个自变量的这个系数，我们称为偏回归系数。呃，具体的这个求解的方法呀，
我们就不关注了，这个呢，书上也没有写，而且这也不是重点。呃，它很复杂，一般来说呢，我们在证明的时候，呃，会使用矩阵运算。呃，如果说是这个自变量个数多，还要用解方程的方法，那就呃，太繁琐了，
我们重点关注的是这个偏回归系数的含义。就是我们得到这个估计值，以后该怎么解释这些偏回归系数呢？比如说我们现在得到了一个。呃，估计的结果。比这个beta 1 hat。等于零点零四，那这个零点零四它的含义是什么？它的含义是在其它变量不变的条件下。x1每增加一个单位y，平均会增加零点零四个单位。首先，什么是在其他变量不变的条件下。我们现在解释的是x1的偏回归系数的含义，
那么其他的变量就是x2x3和x。我觉得这三个变量。不变叫其他变量不变，然后x1每增加一个单位。y啊，平均会增加零点零四个单位，那这个时候我这个一个单位是多少呢？这个时候就要看。呃，实际含义了，比方说现在x1啊，表示年龄。咱们假设啊。y呢？表示收入。
单位是万元，那么这个零点零四就是说在其他变量不变的条件下。年龄每增加。一岁啊，年龄的单位是岁啊，年龄每增加一岁。收入平均会增加零点零四。万元啊，这个是它的含义。那如果系数和边回归系数出现了负值，那比方说这个负零点零二九。呃，那它的含义呢？就是说。在其他变量不变的条件下，
那这个时候其他变量就是x1x2和x3。不变的条件下。x4每增加一个单位。每增加一个单位。那么y平均会下降零点零二九个单位。啊，那么系数偏回归线是正的。这个变量增加y平均就增加ph v系数是负的，这个变量增加y平均就会。减少啊，这个是系偏回归系数的含义啊，要看它的正负，同时千万不要忘了前面那句话。在其他变量不变的条件下。还要注意这个影响是对y的平均影响啊，
平均来说会怎么样？那这个是我们关于边缘回归系数的解释。呃，下一步呢，就是对估计的互为方程的评价，评价方程的。拟合优度。那我们首先来看一下多重判定系数。呃在一元回归当中呢，我们学习的是判定系数啊，没有多种两个字，在多元回归当中，我们学习的是多种判定系数。但是呃，不管是多重判定系数还是判定系数，
其实是一回事儿。它都是从因变量的总平方和的分解开始的，不管一元还是多元，因变量总是只有一个的。而且因变量的波动呢，也能分解成两个部分，那么因变量y本身的总波动就是y的。离均差平方和它的自由度是n- 1。那这一部分。平方和是拟合值与总均值之间的。这个离差平方和啊就是。估计值到均值的波动啊，那就是k个自变量合在一起，可以解释的。波动。
那这部分呢？我们称为回归平方和自由度是。剩下的这个波动呢，是真实值到拟合值的波动。它是自变量，不可以解释那一部分。称为残差平方和它的自由度呢？是n-k- 1，那么自由度也会有一个。这样的关系，总平方和的自由度等于两个平方和的自由度之和。我们也可以表示成这样一个关系。那么r方呢就是。自变量呃，可以解释的那部分平方和比上总平方和啊，
表示的就是。自变量可以解释的平方和所占总平方和的一个比例，那我们称为r方啊。是就是多重判定系数，那么依照三个平方和的这一个这样一个关系呢，我们又可以把阿方。啊，写成这样的形式。那到这儿呢，实际上这个r方跟一元回归当中的r方其实是没有什么区别的。呃，但是它既然是这个多元，它应该会有自己的一个特殊性。那么，它的特殊性在哪里呢？
就是呃，在这个多元回归当中呃，如果我们。不断的。呃，增加自变量的个数，那么这个r方是不会减少的，一般而言，它会随着自变量的个数的增加而增加。比如啊，本来我们在这个模型当中就只有两个。四零六。x2啊，我们写成这个估计的形式。那这个方程我们估计完之后呢，
我们可以计算一个r方出来。那如果我现在又想加一个对y的影响因素进去，比如说。我们加一个x3进去。那我们估计完之后呢，我们又可以算一个r方出来。那么，这两个r方的大小关系是这样的。也就是说，我们的自变量的个数增加，会导致这个r方啊，至少是不会减少。一般呢，是增加的。那如那在这种情况下呃，
如果我想提升r方啊，不断的增加自变量就行了嘛。而且。很关键的一点就是我都不用考虑这个加进去的自变量，对因变量有没有影响？那即使这个x3和y之间啊，它毫无关系。我就生成一个随机数进去，这个阿尔法它不会变小啊，它大概率还是增加的。那在这种情况下。阿方就不再是一个评价你和优度的良好的指标了啊，因为我可以抛去实际意义，我也可以抛去这个数量上的相关关系。就一个劲儿的加这个自变量，
一个劲儿的使自变量的个数上升。就会导致这个阿方的上升。如果这个时候我们还用拟合优度，还用这个判定系数数去评价这个拟合优度，我们就会觉得这个。r方啊，实际上它已经不是一个好的指标了。啊，那么这个它的原因是什么呢？就是我为什么加次变量的时候？这个r方是会上升的呢？它的原因呢，是这样的，当这个自变量的个数k。增加的时候。
总平方和这个因变量的总平方和它是肯定不会改变的。它会影响回归平方和和三叉平方和。具体的影响呢，是会使得这个回归平环和上升残差，平环和下降，那么我们计算的时候。那回归平衡和ssr上升s ST保持不变，这个r方它就变大。那自变自变量这个个数个数增加的时候呢？呃，剩余平方和ss e会下降。s ST保持不变，那么这个部分就会下降。我们一减这个部分呢。就会导致这个r方的上升。
那这个是它的呃，一个原因，那为了克服r方会随着自变量个数的增加而上升的这样一个缺点呢？我们做呃以下的改进。改进的方式就是我们按照这样一个表达式，把这个分子ss e改成ss e，除以它的自由度。n-k- 1。然后把s ST替换成s ST除，以它自己的自由度n- 1。然后再做比值。那我们改进以后，我们看。随着这个自变量个数的上升。这个r方会表现出一种什么样的变化？
就是我们实际上是把这个整体。啊，这个比值换成了后面。这样一个比值，然后呢，一再减去后面这个比值。如果k。啊，它变大了。会不会影响这个一呢？显然是不会那么会不会影响s ST呢？是不会的。那么n- 1跟自变量的个数也是没有关系的，所以。即使k变大，
也不会影响一。也不会影响这个部分。但是呢，它会使ss e变小。ss e变小。但是与此同时，它的自由度n-k- 1。也会变小。那么，总体来看s sep主这个除以它自己的自由度，这个整体一定会变小吗？啊，这个是不一定的啊，它不一定会变小。那既然现在我们知道了，
做了这样一个改进。之后。啊，这个式子我们把它转换成这样一个式子以后。如果自变量的个数增加，那这个部分的分子和分母同时增加。那么，这个部分整体上来看就不一定是上是下降的啊，它也有可能是上升的。那么，我们进行了这样一个改进之后呢？称把这个呃r方呢称为调整后的r方，即为r方a。啊，调整后的r方，
那我们对这个式子呢？再做一个这个整理。这个部分的分子是ss e。比上n-k- 1分母是s ST比上n- 1，那我们把下面这个部分。给它翻上去就等于ss e比s ST乘上两个自由度之比。n- 1 n-k- 1。那我们看这个。比值实际上就等于原来的r方。那么一减去这个比值呢？就是一减。阿尔法就是它，然后再乘上自由度之比。啊，这个就是一减掉了这个部分，
所以我们把这个比值就换成了这个部分。然后我们把。新的啊，我们改进后的这个r方记为r方a啊，下标是a。它被称为调整后的r方，那么调整后的r方和没有调整之前的r方。它的关系大小关系是什么呢？我们来看一下啊。这个r方，它一定是等于。一键取一键。r方而这个调整后的r方，它等于一减一减r方。成了一个自由度之比n- 1 n-k- 1。
那么，这个自由度之比一定是大于一的。那后面被一减掉的这个部分，相对于一减r方来说就上升了。那被减掉的这个部分上升了那么一减掉它呢，就会下降啊，整体上来说它就下降。所以调整后的r方啊，一定是大于调整，一定是小于调整前的r方的。而且这个调整后的r方是可能小于零的啊。它可以小于零，因为后面呃，我们除以的这个乘以的这个自由度之比啊，这个就要看情况了，
有的时候。呃，因为这个自由度之比，它可能呃特别的大，就会导致这个r方。小于零，所以呢，大家注意一下，如果你自己。呃，去跑一些数据，你发现这个调整后的r方，它是小于零的啊，你也不要惊讶啊，这是理论上可能出现的值。
啊，它跟这个调整之前的r方不一样，调整之前的r方是一定不会小于零的，但是调整后的r方是可以小于零的。那如果一旦这个r方a啊调整后的r方出现了小于零的情况，比如说它。啊，等于负零点零二啊，这个时候呢，就一就一般来说呢，就把这个调整后的r方看成零就好了。啊，因为这个赋值，你如果去解释它的实际含义的时候呢，这个不好解释，
因为本身这个。呃r方也好，调整后的r方也好，它的含义都是说自变量可以解释的那一部分，平方和的占比。啊，它的占比出现了负数啊，这个是不好解释的，所以一旦出现了这种情况，就把它当成零处理。那这个是多重判定系数，下面我们看估计标准误差。那这个跟一元的时候呢，很相似啊，都是剩余平方和ss e除以自由度。
啊，也就是说是呃，剩ss e它是剩余平方和那么呃，除以它的自由度呢，就变成了剩余的均方。啊，这个呢，它也有它自己实际的含义啊，它可以来估计这个sigma方。那码方是谁呢？是这个随机误差项的方差。啊，同时呢，它也可以衡量这个拟合优度啊，因为残差平方和呃，
这个它本身就是。可以衡量剩余的那一部分有多大啊，所以呢，我们呃也是希望啊，剩余的这个。参差平方和也好，还是剩余的这个呃，均方也好，我当然是越小越好嗯，它越小的话呢，就说明这个。呃，样本观测点与拟合的那条直线呢？是越贴近的啊，它越呃紧紧的围绕在这个直线拟合的这个直线附近。
那么这个是方差。标准差呢，就是开个根号就可以了。下面我们看这个。显著性检验包括两个部分，一个是线性关系检验，又称为总体显著性检验。第二个呢，是回归系数的检验和推断。这个逻辑跟我们一元回归的时候的这个逻辑也是一样的，就是两个检验，一个线性关系，一个回归系数。那我们来看这个线性关系检验，又称为总体显著性检验。
那这个总体显著性检验呢呃。我们在一元回归的时候，你可能还不是很明白，只是说这个线性关系检验和这个系数的检验，它的区别在哪里呢？那这个线性关系检验，它是从全局出发。它检验各个自变量合起来，对应变量有没有解释能力？所以他呃不关注说哪个系数等于零啊，哪个系数不等于零啊，他不关注这个，他就关注。你这些自变量合起来，对应变量到底有没有解释能力？
所以它的这个原假设是所有的系数。都等于零啊，其实它这个云假设就是假设，所有的自变量对应变量都没有解释能力。b则假设呢，是不全为零啊，他不关注具体哪个不等于零，他只关注是不是全都等于零。呃，这跟方差分析的这个f检验。是很相似的，那么检验统计量呢？是这个f分子是ssr除以自由度。k分母呢是ss e除以自由度。它服从f分布，
最后都是k和n-k- 1啊，分别就是ssr和ss e的。自由度第三步呢，是做统计决策，那么这个f统计呢，我们是可以根据。样本数据计算得到的。那么，在计算出这个具体的f值以后呢？我们根据显著性水平去确定临界值，然后用。计算得到的f值与临界值做比较，那么这个还是个右侧这一列，当我们计算得到的f等级量的值比临界值大的时候，我们就。
拒绝原假设。否则呢，我们就不拒绝原假设那么大，大于临界值拒绝原假设，就意味着从整体上看，模型的设定是。有意义的啊，还是不管这个到是哪个变量对y产生了解释的能力，反正这里头是有。啊，如果我们拒绝原假设的话，那如果没有拒绝原假设呢？就是说呃，这里头每一个自变量。这个y都没有解释能力，
然后后续的这个系数你都不用检验了，因为从整体上看就否决了这个模型了啊，如果。你不拒绝的话，不拒绝的话，就是意味着这样一个效果，那么这样一个效果已经产生了，实际上就是从。整体上就把这个模型就否决否决掉了啊。那嗯，注意的一点呢，就是这个自由度的问题，我们在医院回归的时候呢，这个自由度是什么呢？这个在医院回归的时候，
这个自由度是？那么，这个自由度是n- 2啊？为什么呢？音乐回归的时候，一表示的是这边的个数。多元回归的时候呢，它还是自变量的个数k，所以这个含义这个式子啊，你可以。记下来。它可以处理多元回归，它也可以处理一元回归。那么，这个n-k-1呢？
是n-2其实就是n-1-1，那么这个一表示意愿回归当中资源的个数啊，所以这个。是指在一元和多元当中，它是通用的。下面我们来看回归系数的检验和推断。呃在一元回归当中呢，我们也有这样一个对回归技术的检验，但是一元回归呢，我们只有一个自变量。所以我们就只检验这一个自变量的系数。贝塔一但是在多元回归当中呢，自变量的个数。增加了x1x2。xk.
假设有k个自变量，每个自变量都有自己的系数啊，所以在对灰系数进行检验的时候呢？有多少个自变量就要做多少次检验啊，逐个对它们的系数进行检验。我们来看，第一步是提出假设对任意的参数。贝塔a。I从一到k有h0贝塔I=0 h1贝塔I不等于零。第二步呢，是计算检验统计量，那这个检验统计量的构造呢？与我们一元回归的构造也是一样的。呃纪元回归当中，我们是只有贝塔一。
所以我们构造的时候呢，是bit in height比上bit in height的。这个这个标准差。它负责t分布精确度是n- 2，那这个是在一元回归当中的情况，在多元回归当中，你检验的是哪一个？参数啊，检验的是哪一个自变量的？系数这里你就把下标相应的更改就行了，比如说我们想检验第二个，那么我们构造的时候就是beta 2。at跟上。贝塔2 hat标准差，它服从的是t分布，
但是这个自由度。要注意一下，这是n-k- 1。因为它的自由度，这个t分母的自由度的来源其实是来源于这个分母啊，这个分母的自由度是n-k- 1导致。这个提分布的自由度呢，也是n-k- 1，那么在一元当中是n- 2，其实就是n- 1。再减一那么这个一是一元回归当中子变量的个数，它就是一。那么这个呃。beta I的。它的标准差嗯，
我们注意一下，这个下标也是I那么这个下标I。它是对应的，是自变量的下标哎，如果说我们估计我们这个检验的是。beta 2那么。分母上应该是x2这个变量。所有取值的一个波动情况。这里要注意一下啊。它都带下标啊，你就要注意要换啊，你检验哪一个你就换成哪一个。最后一步呢，是做出统计决策。那我们对不同的区块链的系数做检验计算，
得到的这个t统计量的值，它们是不一样的。啊，因为他们的估计值和他们的标准差都不一样，所以每一个。系数的这个体统计量都是不一样的，但是如果我们用统一的一个显著性水平阿尔法，它们的临界值。呃，是一样的，那这是一个双侧检验，如果。t的绝对值大于了这个零件时，我们就拒绝原假设。啊，
我们认为这个呃。第I个。自变量对因变量有显著的影响。下面看这个推断就是置信区间啊，这个呃贝塔I hat作为它的估计值。然后加减一个半径，我们这个半径是分位数乘上它自己的标准差。那到现在为止呢，我们可以发现这个多元回归和音源回归我们学习的这个内容，它是很相似的。呃，我们可以把多元理解成一元的一个拓展，可以把一元理解成多元的特例啊，下面我们就介绍一个。多元回归特有的可能出现的问题叫做多重贡献性嗯，
这个多重贡献性它不是个。好事啊，一般来说它不是好事啊，就它会产生一系列的问题，我们看一下什么叫多种共性性。当回归模型中啊，有两个或两个以上的自变量，彼此相关的时候，我们就称模型中存在多重贡献性。那实际上我们在做多元回归的时候，我们如果关心这个各个自变量，对因变量y的影响。我们希望是什么呢？我们希望就是各个词汇量之间呢，你不要有相关的关系，
你对y的影响呢，你就各自影响各自的。哦，这种情况，比如说我们在呃研究这个学生的高考成绩的时候，会涉及到一些家庭方面的因素，比如。呃，父亲的学历，母亲的学历，家庭的收入等等。那么我们这样考虑，其实并没有问题啊，这个父母的学历啊，家庭的收入啊他。
从理论上来说，它就是会影响这个学生的考试成绩的。但是如果一旦我们把父亲的学历，母亲的学历，家庭的收入放到一个模型当中。他就会产生问题，因为这个父亲的学历和母亲的学历，它整体而言，它呈现出一个正相关的关系。而父亲的学历或者母亲的学历与家庭收入，整体上来说也会呈现一个正相关。呃，这会产生的问题是什么呢？就是我们。在研究父亲的学历。
啊，对这个孩子的成绩y的影响的时候可能是啊，这样一个影响。一个影响程度啊，如果我们把母亲加进来啊，母亲的学历加进来之后呢，它可能会是一个这样的影响程度。我们希望的就是你们各自影响各自的，但是这个父亲的学历和母亲的学历，它一旦有了一个正相关的关系。以后这两个影响。它不是这样明显的区分开的。啊，它可能会这样。母亲的学历和父亲的学历会对y的影响产生了一个。
交集，而且这个交集可能会很大，也就是说我们。在这个用父亲学历的基础上，再加了一个母亲的学历进来，这个母亲的学历。对孩子的影响，其实有一部分是与父亲的学历，对孩子的影响是重复的。我们需要重复的影响吗？我们不需要啊，那一旦你有这样的关系，你这个x能够提供的。影响有一部分就重复了，就多余了，
其实重复的这个部分我们是不需要的，因为我们单独用一个父亲呢，就有这一部分，那我们再加一个母亲呢进来。有一个重合啊，会出现这样一个重合，那么这个就是多重共建性，那它会导致导致。两个问题，第一个呢是变量之间高度相关的时候，可能会使这个结果混乱，甚至。呃，把分析引入歧途啊，比如说它可能导致的问题，
我们在做这个。线性关系检验，或者说这个总体显著性检验的时候，这个f统计量它可能很大，它对应的p值。可能很小，也就是说从总体上来看。我们这个模型当中的自变量啊，是对因变量有解释能力的啊，从整体上来看。但是我们对于系数。做单独检验的时候，可能里头只有一个，比如说贝塔一勉强能够通过显著性检验。剩下的从beta 2，
beta 3移直到beta key。都已经通不过检验了。啊，可能会出现这样的问题，那有人可能会说那这个总体显著。并不意味着这些系数全部显著啊，那么总体显著只有呃系数呃当中只有一个显著，那也是一个一个这个正常的现象，理论上来说这个现象是可以存在的。那这个话是对的啊。如果我们仅仅发现这个总体显著性啊，是通过的，但是系数显著性只有一个通过，只剩下的都不通过。这不并不能保证，
一定是问题，但是我们现在说的是。多重贡献性会导致这样的问题，那么如果是多重贡献性导致了一个这样的问题，那这就是问题，这是一件不好的事情。那么，第二个问题，它是可能会对系数估计值的正负号产生影响，可能与预期的正负号相反。比如说我们这个。呃，刚才那个例子啊，父亲的学历，母亲的学历，
家庭的收入，对高考分数的影响，如果。这个存在多重贡献性，我们可能得到的结果是父亲的学历对这个孩子的高考分数是个负向的影响。母亲的这个学历对孩子的高考分数也是个负向的影响，那有人可能会说，这也不是不可能啊。嗯，开始举例子说谁谁家的父母都是小学学历，或者谁谁家的父母都是文盲，但是人家的孩子考上了九八五，考上了清华北大。啊，这个大家要注意啊，
这是特例啊，这是特例，我们统计学研究的是一般情况，平均影响平均而言，整体而言。父母的这个学历预期会对孩子的高考成绩，它应该是产生一个正向的影响。那么，贡献性问题一旦产生啊，导致的问题可能就是说呃，父母的学历预期会对孩子高考成绩产生一个正确的影响，但是结果。这个父亲的学历或者母亲的学历，它前面的系数是个负数，那负数我们解释起来就是说这个。
呃。这个在其他变量不变的。条件下，父亲的学历啊，每增加一个单位。那么，孩子的高考分数平均来说会下降多少啊？这个就产生了这种不合理。那这个是多重共建性的定义和它可能会导致的问题。我们来看一下这个固件性的判别。也就是说，我们观察到模型出现了什么情况的时候，我们就开始要怀疑。我们的模型出现了多重关键性，第一个是模型中各对自变量之间显著相关。
啊，这个显著相关，你就去可以计算这个相关系数啊，当然了，我们也没有讲过这个偏相关系数，也可以计算偏相关系数。比如说我们计算yx 1x2x3。yx 1x2x3，它们之间呢，会构成一个矩阵。x3那么对角线上呢？都是自己跟自己啊，这个是y跟y这个是x1跟x1x2跟x2x3跟x3。那么自己跟自己它的相关系数一定是一，那么下面呢？
我们除了可以计算x1和y。x2和yx 3和y之间还可以计算，比如x1和x2，我们写在这里，它们的相关系数。x1和x3，它们的相关系数，然后x2和x3，它们的相关系数。那么，这个我们只需要在对角线下面填满了之后啊，就可以计算y与各个自变量之间的相关以及。以及自变量之间的相互的相关啊，可以用这样一个表格来表示写上它们相关系数标明。是否显著啊？
来看一下这个自变量之间是不是存在这样的关系，那么如果存在显著相关啊？就意味着这个多重公允性出现了，那么第二个和第三个呢？是我们刚才讲过的多重公允性，可能会导致的问题。那么，一旦这种问题出现了啊，我们也要开始怀疑。是不是？多重共性性存在。呃呃，刚才我们说过了，这个总体显著啊，几乎所有的系数都不显著啊，
或者是回归系数的这种符号与预期的相反。那当然了，这个我们比方说我们跟这个预期的相反，也是一个怀疑啊，那只是一个怀疑，有可能说。啊，我们的理论，我们的预期也不一定就100%正确啊。所以与预期相反，你不能说这个模型一定是错的，但是呢？你可以把它当成一个出问题的暗示啊，去再去检验一下这个模型是不是就是存在做中圆形的问题？第四个呢，
是容忍度和方差扩大因子，或者叫方差膨胀因子。那么，什么是叫容忍度？是一减r方i，这个r方i是什么？我们讲一下。呃，本来我们的这个模型是这样的。那就是这样的，我们要计算这个容忍度，每一个自变量x从x一直到xk。都对应着一个容忍度，也就是说我们这个容忍度有k个那么x1对应的容忍度是怎么得来的呢？是这样的。
我们把x1啊，就作为自变量，作为因变量啊，从这它就不作为自变量了。然后y呢？就不用啊，把这个地方就直接换成x1。去做这样一个回归，那么这个回归是x1和其他自变量的回归。我们照样可以计算一个r方啊，这个r方就是r方一啊，就是自变量。x1作为因变量对其他自变量做回归得到的这个r方啊是r方一。然后一减去。r方嗯，
就是自变量x1，它的容忍度。发热浓度我们可以想一下，如果这个r方。f方一它特别大。就会导致这个容忍度。下降会变小，那么它小到什么时候，我们就认为。存在这个严重的多重贡献性呢？当它小于。零点一的时候，那它小于零点一，意味着这个r方r1的平方，比如说啊，
它已经是大于零点九了。它大概零点九。说明什么呀？说明这个x1的总的波动当中有90%可以由剩余的自变量来解释。那你说这个x1，它得有多么多余啊，对吧？就你的总的变化都可以用后面的剩余的自变量来解释了啊。那几乎你所有的波动都可以用其余的资源来来解释，那就意味着。x1与其他的变量存在着相关关系了啊，所以这个时候我们认为。它存在。啊，当这个容忍度小于零点一的时候，
我们认为它存在严重的多种无限性。这是啊，容忍度的问题，那你如果计算这个x2的容忍度呢？也就是这个y不要啊，这个x这边这个x2放到这边来做，因变量就会计算一个。这个第二个。自变量对应的容忍度一减r方，那么这个一减r方如果小于零点一的时候，说明存在严重的。固定性问题，那么这个方差膨胀因子是什么呢？方差膨胀因子是这个容忍度的倒数。容忍度的倒数，
我们刚才说这个容忍度如果小于零点一就容易存在严重的贡献性。那么，这个方差因膨胀因子呢？当大于十。当时的时候，我们就认为它出现了严重的多种供电信，当然了，这个。呃，容忍度每一个自变量对应着自己的一个值，那方差膨胀因子呢，也是一样的。所以嗯，我们在这个做模型的时候呃，可以发现啊，
如果我们做这个呃，功能性检验用放大膨胀因子或者是用容忍度的时候。就每一个自变量。它都对应着自己的一个容忍度。啊，会有这样一个表格出现，到时候你就。按照评价标准去看哦，到底哪一个资金量的容忍度是小于零点一了，或者是哪一个是大于十了？就意味着。这个变量跟其他变量之间是显著相关，是存在这个线性关系的，就意味着这个自变量的波动。是可以用其他词变量的波动啊解释的。
或者说这个这个词变量的波动。有很大的比例啊，超过比如说它小于零点一了，就意味着这个自变量的波动。当中超过90%可以由其他自变量的波动来解释，那这个自变量那就太多余了。那这个是多重共建性的判别，我们来看一下多重共建性问题的处理。第一呢，是将一个或者多个相关的自变量从模型当中剔除啊，使保留的自变量尽可能的不相关。嗯，这个是很好理解的，比如我们发现这个呃x2，它的容忍度小于零点一了，
或者它的放大扩大因子大于十了。那这个x2我们就可以从模型当中把它删掉。然后呢，再去检验剩下的自变量之间会不会也存在这种情况，如果存在的话呢，你就可以删掉它。第二个呢，是如果要在模型中保留所有的自变量，就应该第一个避免根据t统计量对单个参数进行检验。那这个呢，大家可能会觉得奇怪，说呃已经出现了多重关键性了，你不去删变量，同时呢，你还对这个。
呃，单个参数的检验呢，进行回避，那这不是掩耳盗铃吗？那实际上呢？他说的这个情况是针对一个。呃，特殊的多元回归的呃，研究目的而言的就是预测。预测他关注的是什么，他就关注你预测的好不好，他不关心说这个呃，各个自变量对应变量到底是一个什么样影响他不关心啊？你只要可以预测就好，就可以啊，
你预测的精度高，那我照样可以用，因为我本身。的目的就是预测我并不关注，说这个自变量的系数是不是与其不符合呀？呃，那个自变量的系数是不是说？呃，没有通过显著性检验了，那我本来就不关注这些东西，我就关注预测，那这个时候呢？可以保留，并且呢，对这个单个的检验呢，
就避免一下，根本也不关注它。但是在这个预测的时候。要把这个呃x的值啊，限定在自变量样本值的范围内啊，比如说理论上来说哈，从模模型的角度来说。x1。x2啊，它有它自己的取值范围，理论上来说，比如说它是零到100。它呢，是50到200，那么这是理论上来说，
那么我们抽到的样本x0。啊，我们可能是从十抽到了90x二呢，我们可能是从60抽到了170。啊嗯，这是我们的样本，那我们预测的时候你就不要进行样本外的一个呃样本，取值外的一个预测了。你预测的时候，你比如说。哎，我想知道x1=1x2=52的时候y的值，这个时候它就已经脱离了样本的取值范围。就不要进行这样的预测啊，预测的时候要把这个x1和x2的值分别限定的样本抽到的值。
之内抽到了这个范围之内。对外进行预测。这个是呃，对共间性问题的一个处理，下面我们来看着对立，对这个呃方程进行一个。预测其实这个预测呢，跟我们啊一元当中的预测是一样的，它分为点估计。和区间估计啊，这两种情况又分别对应着均值，个别值均值，个别值。特别值，那么对于点估计来说，
不管是均值还是个别值，只要给定我们x1一直到。x的值。x2x。三比如说它等于七五三二，我们把这个七五三二分别带进去就行了。就可以求出一个y值啊，不管是均值的预测，还是个别值的预测，都可以用这样一种方法带进去。得出一个值，可以作为最均值的，估计也可以作为作为对个别值的预测啊。没有问题，但是区间估计呢，
我们知道在讲亿元的时候，其实这个。对于区间的估计或者个别值的预测就已经很复杂了，那么在多元互为当中呢，我们就直接不接触这个问题了。那一般呢，就这个问题就交给计算机了。啊，计算机它有自己的现成的程序啊，在不同的统计软件上都可以做。你点两下，或者输几行代码，它就知道你要做什么事情了，它就把这个东西答案给你了。下面我们就进入最后一个问题，
变量选择与逐步回归，这也是多元回归特有的一个问题。因为我们在进行这个多元回归的时候，选择自变量的这个阶段，我们可能会。选择呃很多呃，理论上可能会对因变量产生影响的，随便要进来，但这是不是我们要一股脑加进去直接看结果呢？呃，并不是这样，因为我们对这个回归模型，对于所有的回归模型，我们其实都追求一个精简。并不是这个变量越多就越好啊，
我们不希望变量太多。嗯，我们这个精简的方法呢，就是涉及到变量选择和逐步回归，那么这个变量选择和逐步回归呢，有的时候也会用到。这个解决贡献性问题。当中啊，去筛选一些变量。那具体的方法呢，有向前选择，向后剔除和逐步回归，我们来看这个向前选择。向前选择呢，它的第一步啊，
比如说现在呢，我们这个因变量是y自变量是x1x2x3。x4。那么，向前选择它的第一步啊，是对。用这个。y呢去对这个x1x2x3x4分别回归啊，那这里头就有。四个。艺人回归，那么每一个艺人回归呢，都会有一个f动机量。f统计量，我们在这四个应用回归当中，
选择f统计量最大的那个。或者你选择这个f- 1当中p值最小，那个也都行啊，比如说现在我们选定了啊。这个第二个语言回归当中，它的iPhone p量是最大的，那我们就以这个方程为基础。啊，这个方程为基础，分别再加入x1x3和x4。然后再观察。这三个二元的。这个模型它们的f统计量是如何的啊？或者它们对应的p值数值是如何的？那我们也可以。
再依据f统计量。最大。这样一个原则去选，从这三个当中选一个出来。比如说我们现在选择它。那我们选了它之后，下一步呢？啊，在在这个模型上再继续加x。一啊，或者x4进来就会又产生两个。待选的模型啊，方程。那就再去比较加哪个会更好啊？当然了，
这个最好的标准呢呃，其实现在发展的这个方法很多。不一定非要根据咱们统计量去选择啊，但是呢，这个整个的选择的逻辑就是这样的。从一元开始选中一个，在这个一元的基础上再加变量，构成二元。然后再对这个二元的进行选择，选择完之后。二元选择完了，以这个二元为基础，再构造三元。啊，依次往下选，
那如果说按照我们的标准呃，构造完二元再构造两个三元的时候，这两个三元。相对于这个二语言，整体上没有什么明显的改进的时候就可以停下来。就起到了一个这个向前选择去筛选变量的这样一个过程。这个是向前选择，向后剔除啊。那向后剔除它的这个第一步是把所有的自变量都放在模型当中进行回归。然后他再考虑。我分别删除x1，删除x2，删除x3，删除x4以后会对这个。模型产生一个什么样的影响？
当然了，这个判断标准可能会有这个什么f值啊ss e啊？呃r方啊，等等啊，其他的一些呃准则或者方法或者标准，帮助我们来判断我删除哪一个？呃，会比较好，比如说现在我们决定啊。这个第二个比较好，那就在第二个的基础上。再进行。再重复这样一个步骤。我分别删除x1，删除x3，
删除x4啊。会不会对模型有一个更好的改进啊？如果有，那我就选择其中一个啊，选择这个最好的那一个。那如果没有呢，我就停下啊，那这是向后退出它一个向前选择呢，正好是反着来的。呃，大家就是这个能了解他们的基本逻辑就可以啊，因为现在这个呃。变量选择的方法向前，选择向后呃，剔除它们的细节，
其实很多评判的标准也有很多。呃，我们看最后一个，这个逐步回归，那我们在进行向前选择，向后剔除的时候呢？它的这个两种方法其实都是有缺点的，比如说向前选择，它不能反映呃，这个引进新的自变量之后的变化情况。比如说呢，我们从这个呃。yh at=beta 0 hat，再加beta 1 hat x1开始。如果这个时候我们引进了一个。
这个x2。那么，这个x二一旦引进来之后。啊，它就不会被剔除了啊。因为我们如果说从x1到引进x2，那么下一步是什么呢？下一步是说我能不能再观察？呃，引进新的变量，如果能引进新的变量，就引入新的变量，如果不能引进，就停下了。啊，
就停下了，所以一个变量引进来之后，它是不会被剔除的啊，那这种只考虑引入，不考虑剔除的做法呢，是不全面的。那向后剔除呢？首先来说，第一步它就要把资源量全部引入啊，这个计算量大。然后呢，这个自变量一旦被删除，以后就再也没有机会重新进入回归方程了，这就一棍子打死啊，那这个。
向向后删除就是删完以后嗯，比方说这个我们把x2删除了，那么删除以后呢？是我们在这个把x2删除的这个方程为基础，继续往下删。如果我们发现这个呃在删。反而会变得不好了，我们就停下了。啊，已经被删掉了，就永远被删掉了。那这是向前选择和向后删除的。缺点那么植物回归，它的思想是什么？就是向前与向后结合呃，
自变量有进有出，那比如说。呃，我们从呃一开始我们选择了这个x2，它首先进入方程。啊，它首先进入方程，然后我们再考虑在这个一元的基础上去加x1x。三和x4那么经过我们判断呢？我们又把x3加上，才会使这个方程变得更好。那么，这个前两步其实是向前选择的步骤，但是它有了两个自变量之后呢？它要开始。
向后剔除。他要观察一下。比如说这个x3加进来以后。如果x2的系数，它的检验变得不显著了。它就会考虑啊。贝塔二把这个x2删掉变成。只有x3的一个模型。那么这个时候呢，它又开始向前。再选择。再选择那我们看一开始这个从x2加到x3。这是向前向前，如果我们观察到加到x3以后，这个贝塔三是显著的，
但是这个贝塔二不显著了，我们就把。x2删掉了，删掉以后就又只剩x3了。就是x3那么x3，我们想它如果向前选择的时候，会不会有这种可能呢？就是。它又加了一个x4，比如啊。他又加了一个x4起来。好那么x4进来以后呢？如果说这个前面的beta 3又不显著了，它就可以把beta 3删掉。那么beta 3删掉以后，
它再以这个一元的往前加的时候，这个之前被删掉的这个x2。是不是又有机会可以回来呢？对他是有机会的，因为他又要在这个x4的，你这个只有x的这个一元红利当中再考虑。分别加上x1x2和x3的事情，所以这个被删掉了，它还是有可能再回来的。呃，也就是说这个呃，它跟这个呃，只加不减和只减不加？不一样啊，它是向前向后结合啊，
有进有出。这个是逐步回归，那么关于最后呢？就是。呃，你主要理解它的基本思想是在干什么就可以啊？嗯，你如果是考研的话呢？要求严一点，就这个。呃，看一下它的呃文字描述呃。可以稍微记一下。